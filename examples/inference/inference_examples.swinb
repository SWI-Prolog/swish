<div class="notebook">

<div class="nb-cell markdown">
# Welcome to cplint on SWISH

This notebook gives an overview of example programs for inference:

Examples divided by features:
  - continuous random variables: 
  [gaussian_mixture.pl](example/inference/gaussian_mixture.pl), [kalman_filter.pl](example/inference/kalman_filter.pl),
  [kalman_filtermsw.pl](example/inference/kalman_filtermsw.pl),
  [gaussian_mean_est.pl](example/inference/gauss_mean_est.pl),
  [seven_scientists.pl](example/inference/seven_scientists.pl), 
  [widget.pl](example/inference/widget.pl), 
  [widgetmsw.pl](example/inference/widgetmsw.pl),
  [indian_gpa.pl](example/inference/indian_gpa.pl),
  [indian_gpadc.pl](example/inference/indian_gpadc.pl),
  [nballs.pl](example/inference/nballs.pl),
  [nballsdc.pl](example/inference/nballsdc.pl)
  - stochastic logic programs: [slp_pcfg.pl](example/inference/slp_pcfg.pl), [slp_pdcg.pl](example/inference/slp_pdcg.pl) 
  - likelihood weighting: 
  [kalman_filter.pl](example/inference/kalman_filter.pl),
  [kalman_filtermsw.pl](example/inference/kalman_filtermsw.pl),
  [gaussian_mean_est.pl](example/inference/gauss_mean_est.pl),
  [seven_scientists.pl](example/inference/seven_scientists.pl), [widget.pl](example/inference/widget.pl),
  [widgetmsw.pl](example/inference/widgetmsw.pl),
  [indian_gpa.pl](example/inference/indian_gpa.pl),
  [indian_gpadc.pl](example/inference/indian_gpadc.pl),
  [nballs.pl](example/inference/nballs.pl),
  [nballsdc.pl](example/inference/nballsdc.pl)
  - Metropolis-Hastings sampling: 
  [slp.pl](example/inference/slp.pl), [arithm.pl](example/inference/arithm.pl), [gaussian_mixture.pl](example/inference/gaussian_mixture.pl), 
  [widget.pl](example/inference/widget.pl)
  [widgetmsw.pl](example/inference/widgetmsw.pl),
  - rejection sampling: [coinmc.pl](example/inference/coinmc.pl),
  [arithm.pl](example/inference/arithm.pl), [gaussian_mixture.pl](example/inference/gaussian_mixture.pl), [widget.pl](example/inference/widget.pl),
  [widgetmsw.pl](example/inference/widgetmsw.pl)
  - argument sampling: 
  [markov_chain.pl](example/inference/markov_chain.pl),
  [plcg.pl](example/inference/plcg.pl),
  [hmmpos.pl](example/inference/hmmpos.pl), [hmmpos2.pl](example/inference/hmmpos2.pl),
  [arithm.pl](example/inference/arithm.pl), [gaussian_mixture.pl](example/inference/gaussian_mixture.pl), [kalman_filter.pl](example/inference/kalman_filter.pl),
  [kalman_filtermsw.pl](example/inference/kalman_filtermsw.pl),
  [gaussian_mean_est.pl](example/inference/gauss_mean_est.pl),
  [seven_scientists.pl](example/inference/seven_scientists.pl), 
  [widget.pl](example/inference/widget.pl), 
  [widgetmsw.pl](example/inference/widgetmsw.pl),
  [slp_pcfg.pl](example/inference/slp_pcfg.pl), [slp_pdcg.pl](example/inference/slp_pdcg.pl)
  - variable number of objects: 
  [var_objdb.pl](example/inference/var_objdb.pl), [var_obj.pl](example/inference/var_obj.pl)
  - flexible probabilities:
  [flexprob.pl](example/inference/flexprob.pl)
  [persons.pl](example/inference/persons.pl)
  - computation of expectations: [arithm.pl](example/inference/arithm.pl),
  [pctl_slep.pl](example/inference/pctl_slep.pl), 
  - infinite number of explanations:
  [pcfglrdb.pl](example/inference/pcfglrdb.pl),
  [pcfglr.pl](example/inference/pcfglr.pl), [markov_chaindb.pl](example/inference/markov_chaindb.pl), [slp_pcfg.pl](example/inference/slp_pcfg.pl)
  [markov_chain.pl](example/inference/markov_chain.pl),
  [prefix.pl](example/inference/prefix.pl),
  [var_objdb.pl](example/inference/var_objdb.pl), [var_obj.pl](example/inference/var_obj.pl),
  [plcg.pl](example/inference/plcg.pl), [pre_plcg.pl](example/inference/pre_plcg.pl),
  [pctl_slep.pl](example/inference/pctl_slep.pl), 
  [gpl.pl](example/inference/gpl.pl), [rmc.pl](example/inference/rmc.pl),
  [arithm.pl](example/inference/arithm.pl), 
  [truel.pl](example/inference/truel.pl)
  - meta probabilities:
  [meta.pl](example/inference/meta.pl)
  [metacomb.pl](example/inference/metacomb.pl)
  - combining rules: [metacomb.pl](example/inference/metacomb.pl)
  - graphics: 
  [path.pl](example/inference/path.pl),
  [pctl_slep.pl](example/inference/pctl_slep.pl), 
  [hmmpos.pl](example/inference/hmmpos.pl),
  [gaussian_mixture.pl](example/inference/gaussian_mixture.pl), 
  [kalman_filter.pl](example/inference/kalman_filter.pl),
  [kalman_filtermsw.pl](example/inference/kalman_filtermsw.pl),
  [gaussian_mean_est.pl](example/inference/gauss_mean_est.pl),
  [seven_scientists.pl](example/inference/seven_scientists.pl), 
  [widget.pl](example/inference/widget.pl),
  [widgetmsw.pl](example/inference/widgetmsw.pl)
  - Monte Carlo unconditional inference: [coinmc.pl](example/inference/coinmc.pl), 
  [pcfglr.pl](example/inference/pcfglr.pl), 
  [markov_chain.pl](example/inference/markov_chain.pl),
  [prefix.pl](example/inference/prefix.pl),
  [var_obj.pl](example/inference/var_obj.pl),
  [plcg.pl](example/inference/plcg.pl), [pre_plcg.pl](example/inference/pre_plcg.pl),
  [pctl_slep.pl](example/inference/pctl_slep.pl), 
  [gpl.pl](example/inference/gpl.pl), [rmc.pl](example/inference/rmc.pl),
  [hmmpos.pl](example/inference/hmmpos.pl), [hmmpos2.pl](example/inference/hmmpos2.pl),
  - conditional inference: [threesideddice.pl](example/inference/threesideddice.pl),
  [arithm.pl](example/inference/arithm.pl), [gaussian_mixture.pl](example/inference/gaussian_mixture.pl), [kalman_filter.pl](example/inference/kalman_filter.pl),
  [kalman_filtermsw.pl](example/inference/kalman_filtermsw.pl),
  [gaussian_mean_est.pl](example/inference/gauss_mean_est.pl),
  [seven_scientists.pl](example/inference/seven_scientists.pl), [widget.pl](example/inference/widget.pl),
  [widgetmsw.pl](example/inference/widgetmsw.pl)
  - unconditional inference: [coin.pl](example/inference/coin.pl), [coinmc.pl](example/inference/coinmc.pl), [dice.pl](example/inference/dice.pl), [epidemic.pl](example/inference/epidemic.pl), [earthquake.pl](example/inference/earthquake.pl),
  [sneezing.pl](example/inference/sneezing.pl), [eruption.pl](example/inference/eruption.pl), [mendel.pl](example/inference/mendel.pl), [bloodtype.pl](example/inference/bloodtype.pl),
  [path.pl](example/inference/path.pl), [alarm.pl](example/inference/alarm.pl), [hmm.pl](example/inference/hmm.pl), [pcfg.pl](example/inference/pcfg.pl),
  [uwcse.pl](example/inference/uwcse.pl), [cora.pl](example/inference/cora.pl),
  [mendelc.pl](example/inference/mendelc.pl), [meta.pl](example/inference/meta.pl)
  [metacomb.pl](example/inference/metacomb.pl), [flexprob.pl](example/inference/flexprob.pl),
  [persons.pl](example/inference/persons.pl), [pcfglrdb.pl](example/inference/pcfglrdb.pl),
  [pcfglr.pl](example/inference/pcfglr.pl), [markov_chaindb.pl](example/inference/markov_chaindb.pl),
  [markov_chain.pl](example/inference/markov_chain.pl),
  [prefix.pl](example/inference/prefix.pl), [testdb.pl](example/inference/testdb.pl),
  [var_objdb.pl](example/inference/var_objdb.pl), [var_obj.pl](example/inference/var_obj.pl),
  [plcg.pl](example/inference/plcg.pl), [pre_plcg.pl](example/inference/pre_plcg.pl),
  [pctl_slep.pl](example/inference/pctl_slep.pl), 
  [gpl.pl](example/inference/gpl.pl), [rmc.pl](example/inference/rmc.pl),
  [hmmpos.pl](example/inference/hmmpos.pl), 
  [hmmpos2.pl](example/inference/hmmpos2.pl),
  [truel.pl](example/inference/truel.pl)
  - PRISM syntax: [coinmsw.pl](example/inference/coinmsw.pl),
  [widgetmsw.pl](example/inference/widgetmsw.pl),
  [kalman_filtermsw.pl](example/inference/kalman_filtermsw.pl)
  - Distributional clauses syntax:
  [indian_gpadc.pl](example/inference/indian_gpadc.pl),
  [nballsdc.pl](example/inference/nballsdc.pl)
  - .pl format: [coin.pl](example/inference/coin.pl), 
  [coinmc.pl](example/inference/coinmc.pl), 
  [coinmsw.pl](example/inference/coinmsw.pl),
  [dice.pl](example/inference/dice.pl), [epidemic.pl](example/inference/epidemic.pl), [earthquake.pl](example/inference/earthquake.pl),
  [sneezing.pl](example/inference/sneezing.pl), [eruption.pl](example/inference/eruption.pl), [mendel.pl](example/inference/mendel.pl), [bloodtype.pl](example/inference/bloodtype.pl),
  [path.pl](example/inference/path.pl), [alarm.pl](example/inference/alarm.pl), [hmm.pl](example/inference/hmm.pl), [pcfg.pl](example/inference/pcfg.pl),
  [uwcse.pl](example/inference/uwcse.pl), [cora.pl](example/inference/cora.pl),
  [monty.pl](example/inference/monty.pl), [jail.pl](example/inference/jail.pl), [trigger.pl](example/inference/trigger.pl), [light.pl](example/inference/light.pl), [coin2.pl](example/inference/coin2.pl), [threesideddice.pl](example/inference/threesideddice.pl),
  [mendelc.pl](example/inference/mendelc.pl), [meta.pl](example/inference/meta.pl)
  [metacomb.pl](example/inference/metacomb.pl), [flexprob.pl](example/inference/flexprob.pl),
  [persons.pl](example/inference/persons.pl), [pcfglrdb.pl](example/inference/pcfglrdb.pl),
  [pcfglr.pl](example/inference/pcfglr.pl), [markov_chaindb.pl](example/inference/markov_chaindb.pl),
  [markov_chain.pl](example/inference/markov_chain.pl),
  [prefix.pl](example/inference/prefix.pl), [testdb.pl](example/inference/testdb.pl),
  [var_objdb.pl](example/inference/var_objdb.pl), [var_obj.pl](example/inference/var_obj.pl),
  [plcg.pl](example/inference/plcg.pl), [pre_plcg.pl](example/inference/pre_plcg.pl),
  [pctl_slep.pl](example/inference/pctl_slep.pl), 
  [gpl.pl](example/inference/gpl.pl), [rmc.pl](example/inference/rmc.pl),
  [hmmpos.pl](example/inference/hmmpos.pl), [hmmpos2.pl](example/inference/hmmpos2.pl),
  [arithm.pl](example/inference/arithm.pl), [gaussian_mixture.pl](example/inference/gaussian_mixture.pl), [kalman_filter.pl](example/inference/kalman_filter.pl),
  [kalman_filtermsw.pl](example/inference/kalman_filtermsw.pl),
  [gaussian_mean_est.pl](example/inference/gauss_mean_est.pl),
  [seven_scientists.pl](example/inference/seven_scientists.pl), [widget.pl](example/inference/widget.pl),
  [widgetmsw.pl](example/inference/widgetmsw.pl),
  [slp_pcfg.pl](example/inference/slp_pcfg.pl), [slp_pdcg.pl](example/inference/slp_pdcg.pl),
  [indian_gpa.pl](example/inference/indian_gpa.pl),
  [indian_gpadc.pl](example/inference/indian_gpadc.pl),
  [nballs.pl](example/inference/nballs.pl),
  [nballsdc.pl](example/inference/nballsdc.pl),
  [truel.pl](example/inference/truel.pl)
  - .cpl format: [coin.cpl](example/inference/coin.cpl), [dice.cpl](example/inference/dice.cpl), [epidemic.cpl](example/inference/epidemic.cpl), [earthquake.cpl](example/inference/earthquake.cpl),
  [sneezing.cpl](example/inference/sneezing.cpl), [eruption.cpl](example/inference/eruption.cpl), [mendel.cpl](example/inference/mendel.cpl), [bloodtype.cpl](example/inference/bloodtype.cpl),
  [path.cpl](example/inference/path.cpl), [alarm.cpl](example/inference/alarm.cpl), [hmm.cpl](example/inference/hmm.cpl), [pcfg.cpl](example/inference/pcfg.cpl), 
  [uwcse.cpl](example/inference/uwcse.cpl), [cora.cpl](example/inference/cora.cpl),
  [monty.cpl](example/inference/monty.cpl), [jail.cpl](example/inference/jail.cpl), [trigger.cpl](example/inference/trigger.cpl), [light.cpl](example/inference/light.cpl), [coin2.cpl](example/inference/coin2.cpl), [threesideddice.cpl](example/inference/threesideddice.cpl),
  [mendelc.cpl](example/inference/mendelc.cpl), [meta.cpl](example/inference/meta.cpl)

<a name="#app">Examples divided by application domain:</a>
  - natural language:
  [pcfg.pl](example/inference/pcfg.pl),
  [cora.pl](example/inference/cora.pl),
  [pcfglrdb.pl](example/inference/pcfglrdb.pl),
  [pcfglr.pl](example/inference/pcfglr.pl),
  [prefix.pl](example/inference/prefix.pl), 
  [plcg.pl](example/inference/plcg.pl), [pre_plcg.pl](example/inference/pre_plcg.pl),
  [hmmpos.pl](example/inference/hmmpos.pl), [hmmpos2.pl](example/inference/hmmpos2.pl), [slp_pcfg.pl](example/inference/slp_pcfg.pl), [slp_pdcg.pl](example/inference/slp_pdcg.pl)
  - biology: 
  [path.pl](example/inference/path.pl),  [hmm.pl](example/inference/hmm.pl), 
  - puzzles: [monty.pl](example/inference/monty.pl), [jail.pl](example/inference/jail.pl),
  [indian_gpa.pl](example/inference/indian_gpa.pl),
  [indian_gpadc.pl](example/inference/indian_gpadc.pl)
  - genetics: [mendel.pl](example/inference/mendel.pl), [bloodtype.pl](example/inference/bloodtype.pl), [mendelc.pl](example/inference/mendelc.pl),
  - model checking:
  [markov_chaindb.pl](example/inference/markov_chaindb.pl),
  [markov_chain.pl](example/inference/markov_chain.pl),
  [pctl_slep.pl](example/inference/pctl_slep.pl), 
  [gpl.pl](example/inference/gpl.pl), [rmc.pl](example/inference/rmc.pl),
  - medicine: [epidemic.pl](example/inference/epidemic.pl),
  [sneezing.pl](example/inference/sneezing.pl),
  - games: [coin.pl](example/inference/coin.pl), [coinmc.pl](example/inference/coinmc.pl), [dice.pl](example/inference/dice.pl), [trigger.pl](example/inference/trigger.pl), [coin2.pl](example/inference/coin2.pl), [threesideddice.pl](example/inference/threesideddice.pl),
  [truel.pl](example/inference/truel.pl)
  - social networks:
  [uwcse.pl](example/inference/uwcse.pl)
  - filtering: [kalman_filter.pl](example/inference/kalman_filter.pl),
  [kalman_filtermsw.pl](example/inference/kalman_filtermsw.pl),
  - Bayesian estimation: 
  [gaussian_mean_est.pl](example/inference/gauss_mean_est.pl),
  [seven_scientists.pl](example/inference/seven_scientists.pl)
  - toy: [earthquake.pl](example/inference/earthquake.pl),
   [eruption.pl](example/inference/eruption.pl),
  [alarm.pl](example/inference/alarm.pl), 
   [light.pl](example/inference/light.pl), 
   [meta.pl](example/inference/meta.pl)
  [metacomb.pl](example/inference/metacomb.pl), [flexprob.pl](example/inference/flexprob.pl),
  [persons.pl](example/inference/persons.pl), 
  [testdb.pl](example/inference/testdb.pl),
  [var_objdb.pl](example/inference/var_objdb.pl), [var_obj.pl](example/inference/var_obj.pl),
  [arithm.pl](example/inference/arithm.pl).

<a name="#list">Complete list of examples with description:</a>
  - Coin ([coin.cpl](example/inference/coin.cpl),
   [coin.pl](example/inference/coin.pl)) 
   Throwing a coin with uncertainty on its fairness, 
   from J. Vennekens, S. Verbaeten, and M. Bruynooghe. 
   _Logic programs with annotated disjunctions_. 
   In International Conference on Logic Programming, 
   volume 3131 of LNCS, pages 195-209. Springer, 2004. 
   [coinmc.pl](example/inference/coinmc.pl) is a version for inference with MCINTYRE (Monte Carlo sampling).
 [coinmsw.pl](example/inference/coinmsw.pl) is a version that models the problem with PRISM syntax.
  - Dice ([dice.cpl](example/inference/dice.cpl), 
  [dice.pl](example/inference/dice.pl)) 
  A six-sided die is repeatedly thrown until the outcome is six. 
  From J. Vennekens, S. Verbaeten, and M. Bruynooghe. 
  _Logic programs with annotated disjunctionsi_. In International Conference on Logic Programming, volume 3131 of LNCS, pages 195-209. Springer, 2004.
  - Epidemic ([epidemic.cpl](example/inference/epidemic.cpl), 
  [epidemic.pl](example/inference/epidemic.pl)) 
  Model of the development of an epidemic or a pandemic. 
  From E. Bellodi and F. Riguzzi. _Expectation Maximization over binary decision diagrams for probabilistic logic programs_. Intelligent Data Analysis, 17(2):343-363, 2013.
  - Earthquake ([earthquake.cpl](example/inference/earthquake.cpl), [earthquake.pl](example/inference/earthquake.pl)) Occurrence of an earthquake depending on its possible causes. From F. Riguzzi and N. Di Mauro. _Applying the information bottleneck to statistical relational learning_. Machine Learning, 86(1):89-114, 2012.
  - Medical symptoms ([sneezing.cpl](example/inference/sneezing.cpl), [sneezing.pl](example/inference/sneezing.pl)) Effect of flu and hay fever on the sneezing symptom. From F. Riguzzi and T. Swift. _The PITA system: Tabling and answer subsumption for reasoning under uncertainty_. Theory and Practice of Logic Programming, 27th International Conference on Logic Programming (ICLP'11) Special Issue, 11(4-5), pages 433-449, 2011.
  - Eruption ([eruption.cpl](example/inference/eruption.cpl), [eruption.pl](example/inference/eruption.pl)) Occurrence of an eruption or an earthquake at Stromboli. From Elena Bellodi and Fabrizio Riguzzi. _Structure learning of probabilistic logic programs by searching the clause space_. Theory and Practice of Logic Programming, FirstView Articles, 2014.
  - Mendelian inheritance of the color of pea plants ([mendel.cpl](example/inference/mendel.cpl), [mendel.pl](example/inference/mendel.pl)) Mendelian inheritance of the color of pea plants. From H. Blockeel. _Probabilistic logical models for mendel's experiments: An exercise_. In Inductive Logic Programming, Work in Progress Track, 2004.
  - Mendelian inheritance of human bloodtype ([bloodtype.cpl](example/inference/bloodtype.cpl), [bloodtype.pl](example/inference/bloodtype.pl)) Mendelian inheritance of the bloodtype of people. The problem is to predict the probability of the bloodtype of a person. From Wannes Meert, Jan Struyf, and Hendrik Blockeel. _CP-Logic theory inference with contextual variable elimination and comparison to BDD based inference methods_. Inductive Logic Programming. Springer Berlin Heidelberg, 2010.
  - Path ([path.cpl](example/inference/path.cpl), [path.pl](example/inference/path.pl)) Computing the probability of a path between two nodes in a probabilistic graph. Each edge has a probability of being present. From L. De Raedt, A. Kimmig, and H. Toivonen. _ProbLog: A probabilistic Prolog and its application in link discovery_. In International Joint Conference on Artificial Intelligence, pages 2462-2467, 2007.  By running the query graph(G) you can see a nice picture of the probabilistic graph.
  - Alarm Bayesian network ([alarm.cpl](example/inference/alarm.cpl), [alarm.pl](example/inference/alarm.pl)) The Alarm Bayesian network, from Figure 2 in J. Vennekens, S. Verbaeten, and M. Bruynooghe. _Logic programs with annotated disjunctions_. In International Conference on Logic Programming, volume 3131 of LNCS, pages 195-209. Springer, 2004.
  - Hidden Markov Model ([hmm.cpl](example/inference/hmm.cpl), [hmm.pl](example/inference/hmm.pl)) Hidden Markov model for modeling DNA sequences. The model has three states, q1, q2 and end, and four output symbols, a, c, g, and t, corresponding to the four nucleotides (letter). From Christiansen, H. and Gallagher, J. P. _Non-discriminating arguments and their uses_. In International Conference on Logic Programming. volume 5649 of LNCS, pages 55-69. Springer, 2009.
  - Probabilistic Context Free Grammar ([pcfg.cpl](example/inference/pcfg.cpl),
  [pcfg.pl](example/inference/pcfg.pl)) From  Taisuke Sato and Keiichi Kubota. _Viterbi training in PRISM_. Theory and Practice of Logic Programming, doi:10.1017/S1471068413000677. 
  - UWCSE: link prediction ([uwcse.cpl](example/inference/uwcse.cpl), [uwcse.pl](example/inference/uwcse.pl)) UWCSE university domain. From Wannes Meert, Jan Struyf, Hendrik Blockeel. _CP-Logic Theory Inference with Contextual Variable Elimination and Comparison to BDD Based Inference Methods_. Inductive Logic Programming, pages 96-109. Springer, 2010.
  - Cora: entity resolution ([cora.cpl](example/inference/cora.cpl), [cora.pl](example/inference/cora.pl)) The task is to compute the probability that two bibliographic citations refer to the same paper. From F. Riguzzi. _Speeding up inference for probabilistic logic programs_. The Computer Journal, 57(3):347-363, 2014 adapted from ([the Cora example in alchemy](http://alchemy.cs.washington.edu/)).
  - Monty Hall puzzle([monty.cpl](example/inference/monty.cpl), [monty.pl](example/inference/monty.pl)) From Chitta Baral, Michael Gelfond, and Nelson Rushton. _Probabilistic reasoning with answer sets_. Theory and Practice of Logic Programming 9(1), pages 57-144, 2009.
  - Three-prisoners puzzle ([jail.cpl](example/inference/jail.cpl), [jail.pl](example/inference/jail.pl)) From Peter D. Grunwald and Joseph Y. Halpern. _Updating Probabilities_. Journal of Artificial Intelligence Research 19, pages 243-278, 2003.
  - Russian roulette with two guns ([trigger.cpl](example/inference/trigger.cpl), [trigger.pl](example/inference/trigger.pl)) From J. Vennekens, Marc Denecker, and Maurice Bruynooghe. _CP-logic: A language of causal probabilistic events and its relation to logic programming_. Theory and Practice of Logic Programming, 9(3), pages 245-308, 2009.
  - Negation ([light.cpl](example/inference/light.cpl), [light.pl](example/inference/light.pl)) Example showing the use of negation. From J. Vennekens, Marc Denecker, and Maurice Bruynooghe. _CP-logic: A language of causal probabilistic events and its relation to logic programming_. Theory and Practice of Logic Programming, 9(3), pages 245-308, 2009.
  - Coins ([coin2.cpl](example/inference/coin2.cpl), [coin2.pl](example/inference/coin2.pl)) Throwing two coins with uncertainty on their fairness. From J. Vennekens, S. Verbaeten, and M. Bruynooghe. _Logic programs with annotated disjunctions_. In International Conference on Logic Programming, volume 3131 of LNCS, pages 195-209. Springer, 2004. 
  - Three sided dice ([threesideddice.cpl](example/inference/threesideddice.cpl), 
  [threesideddice.pl](example/inference/threesideddice.pl))
  A three-sided die is repeatedly thrown until the outcome is three. From F. Riguzzi and T. Swift. _The PITA system: Tabling and answer subsumption for reasoning under uncertainty_. Theory and Practice of Logic Programming, 27th International Conference on Logic Programming (ICLP'11) Special Issue, 11(4-5), pages 433-449, 2011. 
  [threesideddicemc.pl](example/inference/threesideddicemc.pl) is a 
  version which adds the possibility of querying for the probability that
  the die lands on face 1 at least once. This query has an infinite number of
  explanations and MCINTYRE is required to answer it.
  - Mendelian inheritance of the color of pea plant - larger family ([mendelc.cpl](example/inference/mendelc.cpl), [mendelc.pl](example/inference/mendelc.pl)) From H. Blockeel. _Probabilistic logical models for mendel's experiments: An exercise_. In Inductive Logic Programming, Work in Progress Track, 2004.
  - Meta probabilities ([meta.cpl](example/inference/meta.cpl), [meta.pl](example/inference/meta.pl)) Probabilities computation in the body of probabilistic clauses (also called Nested probability computation).
  - Max combining rule ([metacomb.pl](example/inference/metacomb.pl)) Meta probabilities for implementing a max combining rule. From De Raedt, Luc, and Angelika Kimmig. _Probabilistic (logic) programming concepts_. Machine Learning (2015): 1-43.
  - Drawing balls from an urn ([flexprob.pl](example/inference/flexprob.pl)) Flexible probabilities (variable probabilistic annotations) that are instantiated at run time. From De Raedt, Luc, and Angelika Kimmig. _Probabilistic (logic) programming concepts_. Machine Learning (2015): 1-43.
  - Sampling persons ([persons.pl](example/inference/persons.pl)) The example models drawing a person at random from a population and computing the probability that it is a male or a female using flexible probabilities (variable probabilistic annotations). From J. Vennekens, S. Verbaeten, and M. Bruynooghe. _Logic programs with annotated disjunctions_. In International Conference on Logic Programming,
  volume 3131 of LNCS, pages 195-209. Springer, 2004.
  - Probabilistic Context Free Left Recursive Grammar. Since the grammar is 
  left recursive, derivations may be infinite so the query may have an infinite
  number of explanations and PITA may not terminate. 
  To ensure termination, a bound on the depth of the derivations of PITA can 
  be imposed ([pcfglrdb.pl](example/inference/pcfglrdb.pl)), at the price 
  of getting only a lower bound on the probability. 
  Alternatively, MCINTYRE can be used 
  ([pcfglr.pl](example/inference/pcfglr.pl))
  that performs approximate inference by sampling and termination is ensured 
  because the infinite branches have probability 0. 
  From Taisuke Sato and Keiichi Kubota. _Viterbi training in PRISM_. 
  Theory and Practice of Logic Programming, doi:10.1017/S1471068413000677. 
  - Model checking of a Markov chain. We want to know what is the likelihood
  that on an execution of the chain from a start state _s_, a final state _t_
  will be reached? The chains may be infinite so the query may have an infinite number of explanations and PITA may not terminate. To ensure termination, a bound on the depth of the derivations of PITA can be imposed 
  ([markov_chaindb.pl](example/inference/markov_chaindb.pl)).
  Alternatively, MCINTYRE can be used
  ([markov_chain.pl](example/inference/markov_chain.pl)).
  From
  Gorlin, Andrey, C. R. Ramakrishnan, and Scott A. Smolka. _Model checking with probabilistic tabled logic programming._ Theory and Practice of Logic Programming 12.4-5 (2012).
  - Prefix probability computation. ([prefix.pl](example/inference/prefix.pl))
  Prefix parser for probabilistic context free grammars.
  The program computes the probability that a string is
  a prefix of a string genated by the grammar.
  From
  T. Sato, P. Meyer, _Tabling for infinite probability computation_, in:
  Intnational Confence on Logic Programming, Vol. 17 of LIPIcs, 2012,
  pp.  348-358.
  T. Sato, P. Meyer, _Infinite probability computation by cyclic explanation
  graphs_, Theory and Practice of Logic Programming 14 (2014) 909-937.
  doi:10.1017/S1471068413000562.
  - Querying a deterministic database ([testdb.pl](example/inference/testdb.pl))
  Deterministic predicates can be defined outside `:-begin/end_lpad.` and 
  queried in the body of probabilistic clauses.
  - Existence uncertainty/unknown objects. 
  The programs models a domain where the number of objects is uncertain.
  In particular, the number of objects follows a geometric distribution
  with parameter 0.3.
  We can ask what is the probability that the object number n exists.
  The goal has an infinite number of explanations so we have to either
  set a depth bound ([var_objdb.pl](example/inference/var_objdb.pl)) or
  use approximate inference ([var_obj.pl](example/inference/var_obj.pl)).
  From
  Poole, David. _The independent choice logic and beyond._ Probabilistic
  inductive logic programming. Springer Berlin Heidelberg, 2008. 222-243.
  - Probabilistic Left-Corner Grammar ([plcg.pl](example/inference/plcg.pl)) 
  A grammar using the rules of a
  context free grammar as a PCFG  but using a shift-reduce parser with 
  probabilities assigned to shift-reduce operations. Version with a left
  recursive grammar with MCINTYRE for inference.
  From Sato, Taisuke, Yoshitaka Kameya, and Kenichi Kurihara. 
  _Variational Bayes via propositionalized probability computation in PRISM._ 
  Annals of Mathematics and Artificial Intelligence 54.1-3 (2008): 135-158.
  - Prefix parser for a Probabilistic Left-Corner Grammar 
  ([pre_plcg.pl](example/inference/pre_plcg.pl)) From
  T. Sato, P. Meyer, _Tabling for infinite probability computation_, in:
  Intnational Confence on Logic Programming, Vol. 17 of LIPIcs, 2012,
  pp.  348-358.
  T. Sato, P. Meyer, _Infinite probability computation by cyclic explanation
  graphs_, Theory and Practice of Logic Programming 14 (2014) 909-937.
  doi:10.1017/S1471068413000562.
  - Model checking of the Synchronous Leader Election Protocol expressed in 
  Probabilistic Computation Tree Logic (PCTL).
  ([pctl_slep.pl](example/inference/pctl_slep.pl)) 
  From
  Gorlin, Andrey, C. R. Ramakrishnan, and Scott A. Smolka. "Model checking with 
  probabilistic tabled logic programming." Theory and Practice of Logic 
  Programming 12.4-5 (2012): 681-700.
  This program was kindly provided by Andrey Gorlin and adapted to MCINTYRE
  by Fabrizio Riguzzi.
  - Model checker for fuzzy formulas in generalized probabilistic logic,
  an expressive logic based on the modal mu-calculus for probabilistic
  systems. ([gpl.pl](example/inference/gpl.pl)) 
  From
  Gorlin, Andrey, C. R. Ramakrishnan, and Scott A. Smolka. "Model checking with 
  probabilistic tabled logic programming." Theory and Practice of Logic 
  Programming 12.4-5 (2012): 681-700.
  This program was kindly provided by Andrey Gorlin and adapted to MCINTYRE
  by Fabrizio Riguzzi.
  - Model checker for Recursive Markov Chains expressed in
  generalized probabilistic logic. ([rmc.pl](example/inference/rmc.pl)) 
  From
  Gorlin, Andrey, C. R. Ramakrishnan, and Scott A. Smolka. "Model checking 
  with probabilistic tabled logic programming." 
  Theory and Practice of Logic Programming 12.4-5 (2012): 681-700.
  This program was kindly provided by Andrey Gorlin and adapted to MCINTYRE
  by Fabrizio Riguzzi.
  - Hidden Markov model for part-of-speech tagging.  ([hmmpos.pl](example/inference/hmmpos.pl))
  The states represent parts-of-speech, and the symbols emitted by the states 
  are words. The assumption is that a word depends probabilistically on just 
  its own part-of-speech (i.e. its tag) which in turn depends on the 
  part-of-speech of the preceding word (or on the start state in case 
  there is no preceding word).
  From
  http://www.ling.gu.se/~lager/Spaghetti/spaghetti.html
  Original program by Torbjorn Lager, adapted to MCINTYRE by Fabrizio Riguzzi.
  Argument sampling to approximately compute the Viterbi path (most probable
  tagging).
  - 1st- and 2nd-order Hidden Markov model for part-of-speech tagging 
  ([hmmpos2.pl](example/inference/hmmpos2.pl)).
  This program differs from ([hmmpos.pl](example/inference/hmmpos.pl)) because
    1. a 1st-order HMM and a 2nd-order HMM are included
    2. the probabilistic predicates =trans/3=, =trans2/4=, =out/3= and =out2/4= are defined intensionally
    3. the probability values are defined on the basis of frequency data from a
       (toy in this example) dataset
  From
  Joakim Nivre. "Logic programming tools for probabilistic 
  part-of-speech tagging." Master's thesis, Vaxjo University, 2000. 
  [[pdf](http://stp.lingfil.uu.se/~nivre/docs/thesis3.pdf)]
  Original program by Joakim Nivre and Torbjorn Lager, adapted to MCINTYRE by Fabrizio Riguzzi.
  - Random arithmetic function from http://forestdb.org/models/arithmetic.html
  ([arithm.pl](example/inference/arithm.pl)).
  The model generatively defines a random arithmetic function.
  The problem is to predict the value returned by the function given one or
  two couples of input-output, i.e., to compute a conditional probability.
  Translated from the Church functional probabilistic programming language.
  Sampling is necessary as queries have an infinite number of explanations.
  Both rejection sampling and Metropolis/Hastings can be applied.
  - Gaussian mixture model
  ([gaussian_mixture.pl](example/inference/gaussian_mixture.pl)).
  Mixture of two Gaussians. A biased coin is thrown, if it lands heads X in mix(X)
  is sampled from a Gaussian with mean 0 and variance 1. if it lands tails X is
  sampled from a Gaussian with mean 5 and variance 2.
  The example illustrates the use of continuous random variables and 
  the use of sampling, including
  rejection sampling and Metropolis/Hastings. Moreover the example
  illustrates the use of the predicate histogram/3 for graphing the
  probability density function of continuous random variables.
  - One-dimensional  Kalman filter
  ([kalman_filter.pl](example/inference/kalman_filter.pl), PRISM syntax
  [kalman_filtermsw.pl](example/inference/kalman_filtermsw.pl)).
  Hidden Markov model with a real
  value as state and a real value as output. The next state is given by
  the current state plus Gaussian noise (mean 0 and variance 2 in this example)
  and the output is given by the current state plus Gaussian noise (mean
  0 and variance 1 in this example).
  Given that at time 0 the value 2.5 was
  observed, what is the distribution of the state at time 1 (filtering problem)?
  Liklihood weighing is used to condition the distribution on evidence on
  a continuous random variable (evidence with probability 0).
  CLP(R) constraints allow both sampling and weighing samples with the same
  program.
  From
  Islam, Muhammad Asiful, C. R. Ramakrishnan, and I. V. Ramakrishnan.
  "Inference in probabilistic logic programs with continuous random variables."
  Theory and Practice of Logic Programming 12.4-5 (2012): 505-523.
  http://arxiv.org/pdf/1112.2681v3.pdf
  Russell, S. and Norvig, P. 2010. Arficial Intelligence: A Modern Approach.
  Third Edition, Prentice Hall, Figure 15.10 page 587
  - Posterior estimation in Bayesian models
  ([gaussian_mean_est.pl](example/inference/gauss_mean_est.pl)).
  We are trying to estimate the true value of a Gaussian distributed random
  variable, given some observed data. The variance is known (2) and we
  suppose that the mean has a Gaussian distribution with mean 1 and variance 5. 
  We take different measurement (e.g. at different times), indexed
  with an integer.
  Given that we observe 9 and 8 at indexes 1 and 2, how does the distribution
  of the random variable (value at index 0) changes with respect to the case of
  no observations?
  From
  http://www.robots.ox.ac.uk/~fwood/anglican/examples/viewer/?worksheet=gaussian-posteriors
  - Seven scientists, posterior estimation in Bayesian models
  ([seven_scientists.pl](example/inference/seven_scientists.pl)).
  Suppose seven scientists all go and perform the same experiment, each collecting
  a measurement xi for i=1,..,7.
  These scientists are varyingly good at their job, and while we can assume each 
  scientist would estimate x correctly on average, some of them may have much more
  error in their measurements than others.
  They come back with the following seven observations:
  [-27.020 3.570 8.191 9.898 9.603 9.945 10.056]
  To model this situation, we put a prior on the mean and the standard deviation
  of the measurements each of the 7 scientists.
  For the mean, we use a Gaussian prior with mean 0 and variance 50^2.
  For the standard deviation, we use a uniform prior between 0 and 25.
  Given the above measurements, what is the posterior distribution of x?
  From
  http://www.robots.ox.ac.uk/~fwood/anglican/examples/viewer/?worksheet=gaussian-posteriors
  - Factory producing widgets
  ([widget.pl](example/inference/widget.pl), PRISM syntax [widgetmsw.pl](example/inference/widgetmsw.pl)).
  Consider a factory with two machines a and b. Each machine produces a widget
  with a continuous feature. A widget is produced by machine a with probability
  0.7 and by machine b with probability b.
  If the widget is produced by machine a, the feature is distributed as a
  Gaussian with mean 2.0 and variance 1.0.
  If the widget is produced by machine b, the feature is distributed as a
  Gaussian with mean 3.0 and variance 1.0.
  The widget then is processed by a third machine that adds a random quantity to
  the feature distributed as a Gaussian with mean 0.5 and variance 1.5.
  What is the distribution of the feature?
  Adapted from
  Islam, Muhammad Asiful, C. R. Ramakrishnan, and I. V. Ramakrishnan.
  "Inference in probabilistic logic programs with continuous random variables."
  Theory and Practice of Logic Programming 12.4-5 (2012): 505-523.
  http://arxiv.org/pdf/1112.2681v3.pdf
  - Stochastic logic program [slp_pcfg.pl](example/inference/slp_pcfg.pl).
  Probabilistic contect-free grammar implemented as a Stochastic Logic Program.
  SLPs define a distribution over arguments of goals.
  SLPs can be written as an LPAD/ProbLog program by 
  recalling that in SLPs the probabilities of all rules with the same head predicate sum to one and define a mutually exclusive choice on how to continue a proof.
  Furthermore, repeated choices are independent, i.e., no stochastic memoization
is done.
  - Stochastic logic program [slp_pdcg.pl](example/inference/slp_pdcg.pl).
  Program modeling an SLP defining a probabilistic definite clause grammar.
  Form https://dtai.cs.kuleuven.be/problog/tutorial/various/06_slp.html#stochastic-logic-programs
  - The Indian GPA Problem. 
  ([indian_gpa.pl](example/inference/indian_gpa.pl), distributional clauses
  version [indian_gpadc.pl](example/inference/indian_gpadc.pl)). From
    http://www.robots.ox.ac.uk/~fwood/anglican/examples/viewer/?worksheet=indian-gpa 
  "This example was inspired by Stuart Russell...the problem is: if you observe 
  that a student GPA is exactly 4.04.0 in a model of transcripts of students 
  from the USA (GPA's from 0.00.0 to 4.04.0 and India (GPA's from 0.00.0 to 
  10.010.0) what is the probability that the student is from India?... 
  As we know from statistics, given the mixture distribution and given the 
  fact that his/her GPA is exactly 4.04.0, the probability that the student 
  is American must be 1.01.0 
  (i.e. zero probability that the student is from India)."
  Probabilistic logic program from 
  https://github.com/davidenitti/DC/blob/master/examples/indian-gpa.pl
  - Urn and balls, distributional Clauses example.
  ([nballs.pl](example/inference/nballs.pl), distributional clauses syntax [nballsdc.pl](example/inference/nballsdc.pl)).
  From Example 4 of
  Davide Nitti, Tinne De Laet, and Luc De Raedt. Probabilistic logic programming for hybrid relational domains. Machine Learning 103(3), 407-449, 2016.
  http://link.springer.com/article/10.1007/s10994-016-5558-8/fulltext.html
  "We have an urn, where the number of balls n is a random variable and each ball X has a color, material, and size with a known distribution.
  The i-th ball drawn with replacement from the
  urn is named drawn(i)."
  See also
  https://github.com/davidenitti/DC/blob/master/examples/tutorial.pl
  - Truel, or duel among three opponents  
  ([truel.pl](example/inference/truel.pl)).
  See https://en.wikipedia.org/wiki/Truel
</div>
</div>
