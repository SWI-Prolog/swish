<div class="notebook">

<div class="nb-cell markdown">
# Machines
In this section we will see how to learn the parameters given a background and initial program.

*Note*: the learning algorithms are available only if you use the Prolog editor.

## Writing the program step by step
To execute a learning algorithm the input source must be divided in five parts:
- preamble,
- background knowledge, i.e., knowledge valid for all interpretations,
- Initial LPAD program for you which you want to learn the parameters (optional),
- language bias information,
- example interpretations.

He we will define a program step by step and then execute the EMBLEM algorithm which learns the parameters of a given initial LPAD program. For more information of how to perform learning see the manual *Help*-&gt;*Help on cplint* ([PDF version](https://github.com/friguzzi/cplint/blob/master/doc/help-cplint.pdf)).

### Preamble
In order to perform either EMBLEM or SLIPCOVER you need to import the library =slipcover= with the command
</div>

<div class="nb-cell program prolog">
:- use_module(library(slipcover)).
</div>

<div class="nb-cell markdown">
After that you have to initialize =slipcover= with the command
</div>

<div class="nb-cell program prolog">
:- sc.
</div>

<div class="nb-cell markdown">
At this point you can start setting parameters for SLIPCOVER with the predicate set_sc/2. For the complete list of the available parameters and their meanings see the manual *Help*-&gt;*Help on cplint*. In our example we will set the following parameters
</div>

<div class="nb-cell program prolog">
:- set_sc(depth_bound,false).
:- set_sc(neg_ex,given).
:- set_sc(megaex_bottom,15).
:- set_sc(max_iter,10).
:- set_sc(max_iter_structure,50).
:- set_sc(verbosity,1).
</div>

<div class="nb-cell markdown">
### Background knowledge
We have defined the preamble, now we can specify the background knowledge with a fact of the form
==
bg(&lt;list of terms representing clauses&gt;).
== 
Alternatively, we can specify a set of clauses by including them in a section between the goals =|:- bg.|= and =|:- end_bg.|=. We will use this last approach.
</div>

<div class="nb-cell program prolog">
component(C):-
  replaceable(C).
component(C):-
  not_replaceable(C).
replaceable(gear).
replaceable(wheel).
replaceable(chain).
not_replaceable(engine).
not_replaceable(control_unit).
not_worn(C):-
  component(C),
  \+ worn(C).
one_worn:-
  worn(_).
none_worn:-
  \+ one_worn.
</div>

<div class="nb-cell markdown">
### Initial program
At this point we can define an initial program for which you want to learn the parameters. We can do it with a fact of the form
==
in(&lt;list of terms representing clauses&gt;).
==
Alternatively, you can specify an input program in a section between =|:- in.|= and =|:- end_in.|=. We will use the latter method. Therefore in our example
</div>

<div class="nb-cell program prolog">
:- in.
class(sendback):0.5 :-
  worn(A),
  not_replaceable(A).

class(fix):0.6 :-
  worn(A),
  replaceable(A).

class(ok):0.5 :-
  not_worn(_A).
:- end_in.
</div>

<div class="nb-cell markdown">
### Language Bias
The language bias part contains the declarations of the input and output predicates.

The typical input for EMBLEM will be a set of interpretations, i.e. sets of grounds facts. Among the predicates for the input facts the use has to indicate which are the output predicates. Output predicates are declared as 
==
output(&lt;predicate&gt;/&lt;arity&gt;).
==
In our example
</div>

<div class="nb-cell program prolog">
output(class/1).
</div>

<div class="nb-cell markdown">
Input predicates are those whose atoms you are not interested in predicting.

You can declare *closed world input predicates* with
==
input_cw(&lt;predicate&gt;/&lt;arity&gt;).
==

For these predicates, the only true atoms are those in the interpretations and those derivable from them using the background knowledge, the clauses in the
input/hypothesized program are not used to derive atoms for these predicates.
Moreover, clauses of the background knowledge that define closed world input predicates and that call an output predicate in the body will not be used for deriving examples.
In our example
</div>

<div class="nb-cell program prolog">
input_cw(replaceable/1).
input_cw(not_replaceable/1).
input_cw(worn/1).
input_cw(not_worn/1).
input_cw(none_worn/0).
</div>

<div class="nb-cell markdown">
Besides closed world input predicate we can declare 
*open world input predicates* with
==
input(&lt;predicate&gt;/&lt;arity&gt;).
==

In our example we do not have open world input predicates.

### Example interpretations
The last part of the file contains the data. You can specify data with two modalities: models and keys.

In the models type, you specify an example as a list of Prolog facts initiated by =|begin(model(&lt;name&gt;)).|= and terminated by =|end(model(&lt;name&gt;)).|=.

Alternatively, with the keys modality, you can directly write the facts and the first argument will be interpreted as a model identifier.

The two modalities, models and keys, can be mixed in the same source.

If we use the model modality for the example 1
</div>

<div class="nb-cell program prolog">
begin(model(1)).
class(sendback).
neg(class(fix)).
neg(class(ok)).
worn(gear).
worn(engine).
end(model(1)).
</div>

<div class="nb-cell markdown">
Instead, if we use the key modality, our example will be (note the first term of each fact)
</div>

<div class="nb-cell program prolog">
class(1,sendback).
neg(1,class(fix)).
neg(1,class(ok)).
worn(1,gear).
worn(1,engine).
</div>

<div class="nb-cell markdown">
Then we must indicate how the examples are divided in folds with facts of the form: 
==
fold(&lt;fold_name&gt;,&lt;list of model identifiers&gt;)
==
as for example
</div>

<div class="nb-cell program prolog">
fold(train1,[1,2,3]).
fold(train2,[4,5,6,7,8,9,10]).
</div>

<div class="nb-cell markdown">
we can define intensionally the folds as in
</div>

<div class="nb-cell program prolog">
fold(all_folds,F):-
findall(I,int(I),F).
</div>

<div class="nb-cell markdown">
However, if we define the fold intensionally, we must write those commands after the examples.
</div>

<div class="nb-cell markdown">
## Full program 
Below there is the complete source
</div>

<div class="nb-cell program prolog">
%%%%%%%%%%%%
% PREAMBLE %
%%%%%%%%%%%%
:-use_module(library(slipcover)).

:- if(current_predicate(use_rendering/1)).
:- use_rendering(c3).
:- use_rendering(lpad).
:- endif.

:-sc.

:- set_sc(depth_bound,false).
:- set_sc(neg_ex,given).
:- set_sc(megaex_bottom,15).
:- set_sc(max_iter,10).
:- set_sc(max_iter_structure,50).
:- set_sc(verbosity,1).

%%%%%%%%%%%%%%%%%%%%%%%%
% BACKGROUND KNOWLEDGE %
%%%%%%%%%%%%%%%%%%%%%%%%
:- bg.
component(C):-
  replaceable(C).
component(C):-
  not_replaceable(C).
replaceable(gear).
replaceable(wheel).
replaceable(chain).
not_replaceable(engine).
not_replaceable(control_unit).
not_worn(C):-
  component(C),
  \+ worn(C).
one_worn:-
  worn(_).
none_worn:-
  \+ one_worn.
:- end_bg.
%%%%%%%%%%%%%%%%%%%
% INITIAL PROGRAM %
%%%%%%%%%%%%%%%%%%%
:- in.
class(sendback):0.5 :-
  worn(A),
  not_replaceable(A).

class(fix):0.6 :-
  worn(A),
  replaceable(A).

class(ok):0.5 :-
  not_worn(_A).
:- end_in. 
%%%%%%%%%%%%%%%%%
% LANGUAGE BIAS %
%%%%%%%%%%%%%%%%%
% output predicates
output(class/1).
% input closed world predicates
input_cw(replaceable/1).
input_cw(not_replaceable/1).
input_cw(worn/1).
input_cw(not_worn/1).
input_cw(none_worn/0).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EXAMPLES (interpretations) %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
begin(model(1)).
class(sendback).
neg(class(fix)).
neg(class(ok)).
worn(gear).
worn(engine).
end(model(1)).

begin(model(2)).
class(ok).
neg(class(sendback)).
neg(class(fix)).
end(model(2)).

begin(model(3)).
class(fix).
neg(class(sendback)).
neg(class(ok)).
worn(gear).
end(model(3)).

begin(model(4)).
class(sendback).
neg(class(fix)).
neg(class(ok)).
worn(engine).
end(model(4)).

begin(model(5)).
class(fix).
neg(class(sendback)).
neg(class(ok)).
worn(gear).
worn(chain).
end(model(5)).

begin(model(6)).
class(fix).
neg(class(sendback)).
neg(class(ok)).
worn(wheel).
end(model(6)).

begin(model(7)).
class(sendback).
neg(class(fix)).
neg(class(ok)).
worn(wheel).
worn(control_unit).
end(model(7)).

begin(model(8)).
class(ok).
neg(class(sendback)).
neg(class(fix)).
end(model(8)).

begin(model(9)).
class(fix).
neg(class(sendback)).
neg(class(ok)).
worn(wheel).
worn(chain).
end(model(9)).

begin(model(10)).
class(sendback).
neg(class(fix)).
neg(class(ok)).
worn(engine).
worn(chain).
end(model(10)).

begin(model(11)).
class(sendback).
neg(class(fix)).
neg(class(ok)).
worn(engine).
worn(control_unit).
end(model(11)).

begin(model(12)).
class(fix).
neg(class(sendback)).
neg(class(ok)).
worn(chain).
worn(wheel).
worn(gear).
end(model(12)).

begin(model(13)).
class(sendback).
neg(class(fix)).
neg(class(ok)).
worn(chain).
worn(wheel).
worn(gear).
worn(engine).
end(model(13)).

begin(model(14)).
class(ok).
neg(class(sendback)).
neg(class(fix)).
end(model(14)).

begin(model(15)).
class(fix).
neg(class(sendback)).
neg(class(ok)).
worn(wheel).
worn(gear).
end(model(15)).

fold(all, F) :- findall(I,int(I),F).
</div>

<div class="nb-cell markdown">
### Execute parameter learning
To execute the parameter learning algorith EMBLEM, execute the query with the form
==
induce_par(&lt;list of folds&gt;,P).
==
where &lt;list of folds&gt; is a list of the folds for training and =P= will contain the
input program with updated parameters.

In our example we want to learn the parameters by using all the folds. Therefore
</div>

<div class="nb-cell query">
induce_par([all],P).
</div>

<div class="nb-cell markdown">
--
Complete example: [mach.pl](example/mach.pl)

--
* Based on: The ACE Data Mining System User's Manual https://dtai.cs.kuleuven.be/ACE/doc/ACEuser-1.2.16.pdf

--
For more information about how to perform learning and EMBLEM see the manual *Help*-&gt;*Help on cplint* (or [PDF version](https://github.com/friguzzi/cplint/blob/master/doc/help-cplint.pdf)) and the papers:

[1] Elena Bellodi and Fabrizio Riguzzi. EM over binary decision diagrams for probabilistic logic programs. In Proceedings of the 26th Italian Conference on Computational Logic (CILC2011), Pescara, Italy, 31 August 31-2 September, 2011.

[2] Elena Bellodi and Fabrizio Riguzzi. EM over binary decision diagrams for probabilistic logic programs. Technical Report CS-2011-01, Dipartimento di Ingegneria, Universit√† di Ferrara, Italy, 2011

[3] Elena Bellodi and Fabrizio Riguzzi. Expectation Maximization over binary decision diagrams for probabilistic logic programs. Intel. Data Anal., 16(6), 2012.

[4] Elena Bellodi and Fabrizio Riguzzi. Structure learning of probabilistic logic programs by searching the clause space. Theory and Practice of Logic Programming, 2013.

--
[Back to Tutorial](tutorial/tutorial.swinb)
</div>

</div>
